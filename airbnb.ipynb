{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AirBnB Data\n",
    "\n",
    "In this problem, we will predict the price of an AirBnB listing as a function of its attributes. \n",
    "\n",
    "Download the dataset from this source: https://www.kaggle.com/c/airbnblala/data#\n",
    "\n",
    "We now import all of the modules we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reminder: you can install packages (eg, statsmodels) with \n",
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "import random as rand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we load the data. We will also print a list of each columns together with its datatype, using the \"type\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(26)\n",
    "df = pd.read_csv() # Load in the downloaded csv file \n",
    "\n",
    "feature_names = df.columns\n",
    "for i in range(96):\n",
    "    print(str(i), \"\\t\", str(feature_names[i]),\"\\t\\t\\t\", str(type(df.iloc[0,i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Train / Test Split\n",
    "\n",
    "The price columns, 61, 62, and 63, are our labels; the rest of the columns are our features. We now will generate a data matrix ($X$ from class), use column 61 as a target vector ($y$ from class), and create a train/test split so that we can empirically test for overfitting.\n",
    "\n",
    "To make the 80 / 20 train test split, we shuffle the data and select the first $80\\%$ as the train data, with $20\\%$ held out for validation.\n",
    "\n",
    "Use the code below to create a train / test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['price'].isna()] # let's only consider the examples for which the price is known\n",
    "df = df.sample(frac = 1) # we shuffle the data so that our train/test split will be truly random\n",
    "\n",
    "train_proportion = 0.8\n",
    "n = len(df)\n",
    "print('Size of dataset: ', str(n))\n",
    "\n",
    "# Put the first ntrain observations in the DataFrame df into the training set, and the rest into the test set\n",
    "t = int(train_proportion * n)\n",
    "\n",
    "target = df['price']\n",
    "price_columns = ['price','weekly_price','monthly_price']\n",
    "data = df.loc[:, ~df.columns.isin(price_columns)]\n",
    "\n",
    "# the following variable records the features of examples in the training set\n",
    "train_x = data.iloc[\n",
    "# the following variable records the features of examples in the test set\n",
    "test_x = data.iloc[\n",
    "# the following variable records the labels of examples in the training set\n",
    "train_y = target[\n",
    "# the following variable records the labels of examples in the test set\n",
    "test_y = target[\n",
    "\n",
    "# let's take a look\n",
    "print('Training dataset: ', train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Real-Valued Data\n",
    "\n",
    "Your first task will be to fit a linear model to the simplest type of data available - the real-valued parameters. Once you fit your model to the train data, you will need to print train and test mean squared error, as well as plot the predicted vs the real price.\n",
    "\n",
    "The starter code includes some data processing routines, as well as a plot function.\n",
    "\n",
    "Now, let's select out all numerical data that might be useful for predicting the price. Here is a list:\n",
    "\n",
    "  - host_listings_count\n",
    "  - host_total_listings_count\n",
    "  - accomodates\n",
    "  - bathrooms\n",
    "  - bedrooms\n",
    "  - guests_included\t\t\n",
    "  - extra_people\n",
    "  - minimum_nights\n",
    "  - maximum_nights\n",
    "  - availability_30\n",
    "  - availability_60\n",
    "  - availability_90\n",
    "  - availability_365\n",
    "  - number_of_reviews\n",
    "  - review_scores_rating\n",
    "  - review_scores_accuracy\n",
    "  - review_scores_cleanliness\n",
    "  - review_scores_checkin\n",
    "  - review_scores_communication\n",
    "  - review_scores_location\n",
    "  - review_scores_value\n",
    "\n",
    "These will be easy to grab, but it's important to also include the following stored as a string:\n",
    "\n",
    "  - beds\n",
    "  - security_deposit\n",
    "  - cleaning_fee\n",
    "  \n",
    "For those, we provide write a utility function, which interprets any non-numerical value as a \"0\", which is an accurate interpretation of \"N\\A\" in this context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"This function converts strings to floating point values \n",
    "# and strings that cannot be represented as a number (like NA) are converted to zeros\"\n",
    "def string_to_float(string):\n",
    "    try:\n",
    "        return float(string)\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "labels_real = [\n",
    "  'host_listings_count',\n",
    "  'host_total_listings_count',\n",
    "  'accommodates',\n",
    "  'bathrooms',\n",
    "  'bedrooms',\n",
    "  'guests_included',\n",
    "  'extra_people',\n",
    "  'minimum_nights',\n",
    "  'maximum_nights',\n",
    "  'availability_30',\n",
    "  'availability_60',\n",
    "  'availability_90',\n",
    "  'availability_365',\n",
    "  'number_of_reviews',\n",
    "  'review_scores_rating',\n",
    "  'review_scores_accuracy',\n",
    "  'review_scores_cleanliness',\n",
    "  'review_scores_checkin',\n",
    "  'review_scores_communication',\n",
    "  'review_scores_location',\n",
    "  'review_scores_value'\n",
    "]\n",
    "\n",
    "\n",
    "labels_string = [\n",
    "    'beds',\n",
    "    'security_deposit',\n",
    "    'cleaning_fee'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the real valued data first and cast it as an numpy array with np.asarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following variable should have as many columns as real variables, and as many rows as examples in the training set    \n",
    "train_vals_real = \n",
    "# the following variable should have as many columns as real variables, and as many rows as examples in the test set\n",
    "test_vals_real = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can extract the specific columns related to these labels, convert them to floats as necessary, but **DO NOT** convert the result to numpy arrays yet. (We will run an asseration test to make sure everything is working as intended.)\n",
    "\n",
    "Use .fillna() and .applymap() methods to apply the string_to_float() function elementwise. In particular, impute NaN values with 0.0 (float valued data). You shouldn't need more than one line per expression below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following variable should have as many columns as string variables, and as many rows as examples in the training set  \n",
    "train_vals_from_string = \n",
    "# the following variable should have as many columns as string variables, and as many rows as examples in the test set      \n",
    "test_vals_from_string = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(train_vals_from_string.applymap(lambda x:type(x)!=str).all(skipna=False).all(skipna=False) == True)\n",
    "assert(test_vals_from_string.applymap(lambda x:type(x)!=str).all(skipna=False).all(skipna=False) == True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we cast them as np arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vals_from_string = np.asarray(train_vals_from_string)\n",
    "test_vals_from_string = np.asarray(test_vals_from_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get to a usable matrix of data, we must concatenate these using \"np.concatenate()\" which concatenates np.array objects together with an appropriately chosen axis. **Don't forget to include the offset term!** You may need to use .reshape() to cast the offset term into an array of the appropriate dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vals = \n",
    "\n",
    "test_vals = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's fit the linear model, compute and print the MSE, and plot the predicted versus the real data.\n",
    "\n",
    "We provide some useful helper functions below, though we ask you to complete the MSE function.\n",
    "\n",
    "Plotting all the test data might significantly slow down this notebook; if that happens, feel free to plot just the first couple hundred points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function just computes the mean squared error\n",
    "def MSE(y, pred):\n",
    "    return # YOUR CODE HERE \n",
    "\n",
    "# This function plots the main diagonal;for a \"predicted vs true\" plot with perfect predictions, all data lies on this line\n",
    "def plotDiagonal(xmin, xmax):\n",
    "    xsamples = np.arange(xmin,xmax,step=0.01)\n",
    "    plt.plot(xsamples,xsamples,c='black')\n",
    "\n",
    "# This helper function plots x vs y and labels the axes\n",
    "def plotdata(x=None,y=None,xname=None,yname=None,margin=0.05,plotDiag=True,zeromin=False):\n",
    "    plt.scatter(x,y,label='data')\n",
    "    plt.xlabel(xname)\n",
    "    plt.ylabel(yname)\n",
    "    range_x = max(x) - min(x)\n",
    "    range_y = max(y) - min(y)\n",
    "    if plotDiag:\n",
    "        plotDiagonal(min(x)-margin*range_x,max(x)+margin*range_x)\n",
    "    if zeromin:\n",
    "        plt.xlim(0.0,max(x)+margin*range_x)\n",
    "        plt.ylim(0.0,max(y)+margin*range_y)\n",
    "    else:\n",
    "        plt.xlim(min(x)-margin*range_x,max(x)+margin*range_x)\n",
    "        plt.ylim(min(y)-margin*range_y,max(y)+margin*range_y)\n",
    "    plt.show()\n",
    "\n",
    "# This function plots the predicted labels vs the actual labels (We only plot the first 1000 points to avoid slow plots)\n",
    "def plot_pred_true(test_pred=None, test_y=None, max_points = 1000):\n",
    "    plotdata(test_pred[1:max_points], test_y[1:max_points],'Predicted', 'True', zeromin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function runs OLS and bypasses any SVD (Singular Value Decomposition) convergence errors by refitting the model\n",
    "def run_OLS(train_y, test_y, train_vals, test_vals):\n",
    "    ols_model = sm.regression.linear_model.OLS(train_y, train_vals)\n",
    "    while True: # Bypasses SVD convergence assertion error\n",
    "        try:\n",
    "            results = ols_model.fit()\n",
    "            break\n",
    "        except:\n",
    "            None\n",
    "            \n",
    "    w = np.array(results.params).reshape([len(results.params),1])\n",
    "\n",
    "    train_pred = np.matmul(train_vals,w)\n",
    "    test_pred = np.matmul(test_vals,w)\n",
    "\n",
    "    train_MSE = MSE(train_y, train_pred.flatten())\n",
    "    test_MSE = MSE(test_y, test_pred.flatten())\n",
    "    \n",
    "    return train_MSE, test_MSE, test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_MSE, test_MSE, test_pred = run_OLS(train_y, test_y, train_vals, test_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train MSE\\t\", str(train_MSE))\n",
    "print(\"Test MSE\\t\", str(test_MSE))\n",
    "\n",
    "plot_pred_true(test_pred.flatten(), test_y) #.flatten() will make sure the dimensions match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two seem to trend in the same direction, but there is still plenty of room for improvement.\n",
    "\n",
    "We are missing some of the most important data, namely, the type of rental. After all, a well-reviewed tent will never cost as much as a poorly-reviewed house. We'll ignore the issue of location for now, because it is significantly thornier.\n",
    "\n",
    "Unfortunately, this data is stored in categorical columns, which require a little more work to utilize. Here are the data parameters:\n",
    "\n",
    "  - property_type\n",
    "  - room_type\n",
    "  - bed_type\n",
    "  - cancellation_policy\n",
    "  - host_response_time\n",
    "  \n",
    "These are all best handled with boolean encoding. It's worth mentioning that there is an additional category which can be handled with one-hot vectors, where more than one entry in the column can be $1$:\n",
    "\n",
    "  - host_verifications\n",
    "\n",
    "There are also many boolean parameters, which might inform the price:\n",
    "\n",
    "  - require_guest_profile_picture\n",
    "  - require_guest_phone_verification\n",
    "  - instant_bookable\n",
    "  - is_business_travel_ready\n",
    "  - has_availability\n",
    "  - is_location_exact\n",
    "  - host_identity_verified\n",
    "  - host_has_profile_pic\n",
    "  - host_is_superhost\n",
    "\n",
    "Let's handle the boolean values first.\n",
    "\n",
    "## c) Boolean Data\n",
    "\n",
    "We've provided a helper function to convert the values stored in the original dataset - \"t\" and \"f\" - into Python \"true\" and \"false.\" Extract the arrays for these parameters, then concatenate this new data with all the data you had previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts from \"t\" and \"f\" into true and false\n",
    "def string_to_bool(string):\n",
    "    return string == 't'\n",
    "\n",
    "bool_labels = [\n",
    "  'require_guest_profile_picture',\n",
    "  'require_guest_phone_verification',\n",
    "  'instant_bookable',\n",
    "  'is_business_travel_ready',\n",
    "  'has_availability',\n",
    "  'is_location_exact',\n",
    "  'host_identity_verified',\n",
    "  'host_has_profile_pic',\n",
    "  'host_is_superhost'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following variable should have as many columns as real variables, and as many rows as examples in the training set   \n",
    "train_bv = \n",
    "# the following variable should have as many columns as real variables, and as many rows as examples in the test set\n",
    "test_bv = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(train_bv.applymap(lambda x:type(x)== bool).all(skipna=False).all(skipna=False) == True)\n",
    "assert(test_bv.applymap(lambda x:type(x)== bool).all(skipna=False).all(skipna=False) == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bv = np.asarray(train_bv)\n",
    "test_bv = np.asarray(test_bv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the real and boolean features to form your X train and test matrices\n",
    "train_vals = \n",
    "\n",
    "test_vals = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, refit, and compute the MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_MSE, test_MSE, test_pred = run_OLS(train_y, test_y, train_vals, test_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train MSE\\t\", str(train_MSE))\n",
    "print(\"Test MSE\\t\", str(test_MSE))\n",
    "\n",
    "plot_pred_true(test_pred.flatten(), test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That didn't help much! In fact, that's not terribly surprising. See what the MSE is if we use only the boolean values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bools =\n",
    "\n",
    "test_bools = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_MSE, test_MSE, test_pred = run_OLS(train_y, test_y, train_bools, test_bools)\n",
    "\n",
    "print(\"Train MSE\\t\", str(train_MSE))\n",
    "print(\"Test MSE\\t\", str(test_MSE))\n",
    "\n",
    "plot_pred_true(test_pred.flatten(), test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact this is not too surprising - the most informative data is going to be categorical, since a well-reviewed tent is never going to cost as much as a poorly reviewed full house.\n",
    "\n",
    "## d) Categorical Data\n",
    "\n",
    "Transform the data into one-hot vectors. The categories are easy to extract using the \"np.unique()\" function.\n",
    "\n",
    "Here, we ask that you contribute a little more to the helper function, since this transformation is not trivial. Notice that the categories are passed as an argument - this is important, in case the test set doesn't have a representation for all of the categories in the training set.\n",
    "\n",
    "Make sure your function is linear in the number of data points (entries in the column) which it processes. You can use the nested loop structure provided, or clever list comprehensions. Bonus points if you use a \"Dataframe\" object in a clever way that makes the function significantly faster.\n",
    "\n",
    "If a category appears in the test set but not in the training set, the \"one hot\" vector should be a vector of zeros for that parameter. (In other words, we one-hot encode only the categories in the training set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_labels = [\n",
    "  'property_type',\n",
    "  'room_type',\n",
    "  'bed_type',\n",
    "  'cancellation_policy',\n",
    "  'host_response_time'\n",
    "]\n",
    "\n",
    "#Sets of all categories in a particular column\n",
    "cats_sets = [train_x.loc[:, label].fillna('NaN').unique() for label in cat_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes a onehot vector for every entry in column given a set of categories 'cats'\n",
    "# Here, 'col' should be the set of unique categories for the input 'column': you can fetch this from 'cats_sets'\n",
    "\n",
    "def onehot(column=None, col=None):\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These may take more than one line of code, since you will need to concatenate several numpy arrays\n",
    "train_cat_vals = \n",
    "test_cat_vals = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the one-hot encoded features with all the data you had previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vals =\n",
    "test_vals ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_MSE, test_MSE, test_pred = run_OLS(train_y, test_y, train_vals, test_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train MSE\\t\", str(train_MSE))\n",
    "print(\"Test MSE\\t\", str(test_MSE))\n",
    "\n",
    "plot_pred_true(test_pred.flatten(), test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're making significant improvements! About $10 \\%$ of the previous MSE can be accounted for with this set of parameters.\n",
    "\n",
    "## e) Set data\n",
    "\n",
    "There is another type of data - stored in the host_verifications column - that we haven't used yet. This is set data, best encoded with a many-hot vector.\n",
    "\n",
    "This particular column does not turn out to be particularly informative, but it is valuable to work with it firsthand.\n",
    "\n",
    "The set data happens to be stored in a format that is very close to a valid declaration of a Python string array, so all we have to do is a little parsing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unparsed_str = train_x.loc[:, 'host_verifications'][0]\n",
    "print(unparsed_str)\n",
    "print(type(unparsed_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_str = train_x.loc[:, 'host_verifications'][0].strip('[]').replace('\\'','').split(', ')\n",
    "print(parsed_str)\n",
    "print(type(parsed_str))\n",
    "print([type(i) for i in parsed_str])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a helper function (using the previos two code blocks as reference) that will parse the strings found in the host_verifications column into appropriate string arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_str(string):\n",
    "    return ### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply this function elementwise to the column host_verifications; note that a column of dataframe is a Series object; and Series object use the method .apply as opposed to .applymap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_vals = \n",
    "test_set_vals =\n",
    "\n",
    "print(train_set_vals[0])\n",
    "print(type(train_set_vals[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the way, if you are working on your project, there is a decent chance that sets were stored in a format similar to what we saw here. Using similar string compositions, you will likely be able to similarly parse the data into Python container types (whether arrays or proper Python sets).\n",
    "\n",
    "Now, take this array of arrays, and turn it into a many-hot vector. You are welcome to use the nested loop structure below, or array comprehensions, or even the DataFrame object if you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the collection of all types we need to worry about.\n",
    "vtypes = train_set_vals.explode().unique()\n",
    "\n",
    "def manyhot(column=None, col=None):\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_vals = \n",
    "test_set_vals = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will attach it to the full list of values used so far, but it won't change the MSE much, unfortunately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vals = \n",
    "\n",
    "test_vals ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_MSE, test_MSE, test_pred = run_OLS(train_y, test_y, train_vals, test_vals)\n",
    "\n",
    "print(\"Train MSE\\t\", str(train_MSE))\n",
    "print(\"Test MSE\\t\", str(test_MSE))\n",
    "\n",
    "plot_pred_true(test_pred.flatten(), test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f) Location, location, location\n",
    "\n",
    "If you remember, a common refrain in Real Estate is \"location, location, location.\" We're treating Manhattan properties with the same formula as Staten Island!\n",
    "\n",
    "The most naive way to include location data would be with the categories \"latitude\" and \"longitude\" - after all, these are continuous variables, so why not include them in the simplest manner possible?\n",
    "\n",
    "Load the longitude and lattitude data in, then try to see what the MSE is if you use *only* these variables,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_labels = ['latitude',\n",
    "             'longitude']\n",
    "\n",
    "train_loc_vals = \n",
    "test_loc_vals = \n",
    "\n",
    "train_loc_vals = \n",
    "test_loc_vals = \n",
    "\n",
    "train_MSE, test_MSE, test_pred = run_OLS(train_y, test_y, train_loc_vals, test_loc_vals)\n",
    "\n",
    "print(\"Train MSE\\t\", str(train_MSE))\n",
    "print(\"Test MSE\\t\", str(test_MSE))\n",
    "\n",
    "plot_pred_true(test_pred.flatten(), test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, this is insufficient. The reality is that price is a highly nonlinear function of location; simply going north or south does not directly translate into rental price.\n",
    "\n",
    "There are several solutions. We could expand our basis of functions, for instance, to use more than linear functions of longitude and lattitude:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_lat = train_loc_vals[:,0]\n",
    "tr_long = train_loc_vals[:,1]\n",
    "train_lv2 = np.transpose( np.vstack([tr_lat, tr_long,\n",
    "                           tr_lat**2, tr_long**2, np.multiply(tr_lat,tr_long)]) )\n",
    "\n",
    "te_lat = test_loc_vals[:,0]\n",
    "te_long = test_loc_vals[:,1]\n",
    "test_lv2 = np.transpose( np.vstack([te_lat, te_long,\n",
    "                           te_lat**2, te_long**2, np.multiply(te_lat,te_long)]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_MSE, test_MSE, test_pred = run_OLS(train_y, test_y, train_lv2, test_lv2)\n",
    "\n",
    "print(\"Train MSE\\t\", str(train_MSE))\n",
    "print(\"Test MSE\\t\", str(test_MSE))\n",
    "\n",
    "plot_pred_true(test_pred.flatten(), test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This helps somewhat with a small nonlinear basis, and a lot with a large basis.\n",
    "\n",
    "There are many different types of nonlinear location basis, of course. We've used a simple polynomial basis above. We might choose a Fourier basis instead; this is especially useful if we believe our data will have strong periodic components, but really this will handle any data in a confined space (assuming our data is sufficiently densely sampled to avoid horrible artefacts).\n",
    "\n",
    "There is a far simpler basis, however, which will work great in our case. Imagine a function that has value $1$ within a specific, closed region - say, an island, or a zip code. Now imagine we have a large list of such functions, which collectively tile the entire region of interest. Bonus points if the regions do not overlap, though that is technically not even necessary.\n",
    "\n",
    "Now, these functions are going to have fewer nice mathematical properties than Fourier features, or wavelets, or even polynomials - two adjacent points will tell us nothing about each other if they are on different sides of one of these artificial borders - but these functions might be very easy to compute. Taking a quick look at the list of columns, it seems we have a number of categorical location parameters to choose from.\n",
    "\n",
    "  - street\n",
    "  - neighbourhood\n",
    "  - neighbourhood_cleansed\n",
    "  - neighbourhood_group_cleansed\n",
    "  - city\n",
    "  - state\n",
    "  - zipcode\n",
    "  - market\n",
    "  - smart_location\n",
    "  - country_code\n",
    "  - country\n",
    "  \n",
    "Use one of the most granular descriptions available - zipcode - and see if that is a good descriptor of location.\n",
    "\n",
    "In the next cell, build a model using this parameter ONLY and print the train and test MSE.\n",
    "\n",
    "Note that it may seem cumbersome to put 'zipcode' in a list, but formatting the one-hot encoding as before ensures the methods are able to handle correct data types (e.g. no data type errors arise between Series vs Dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['zipcode']\n",
    "\n",
    "cats_sets = [train_x.loc[:,i].fillna('NaN').unique() for i in l]\n",
    "print(\"Number of categories\\t\", len(cats_sets[0]))\n",
    "\n",
    "train_zip = \n",
    "test_zip = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now add an offset feature to 'train_zip' & 'test_zip' to create 'train_zip_only' & 'test_zip_only' and then fit your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_zip_only = \n",
    "test_zip_only = \n",
    "\n",
    "train_MSE, test_MSE, test_pred = run_OLS(train_y, test_y, train_zip_only, test_zip_only)\n",
    "\n",
    "print(\"Train MSE\\t\", str(train_MSE))\n",
    "print(\"Test MSE\\t\", str(test_MSE))\n",
    "\n",
    "plot_pred_true(test_pred.flatten(), test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might not look like much, but it's certainly better than raw longitude and lattitude. Compound the zip code data with the features that we've already accumulated, and print out the MSE scores and draw the plots for the full set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vals = \n",
    "\n",
    "test_vals = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_MSE, test_MSE, test_pred = run_OLS(train_y, test_y, train_vals, test_vals)\n",
    "\n",
    "print(\"Train MSE\\t\", str(train_MSE))\n",
    "print(\"Test MSE\\t\", str(test_MSE))\n",
    "\n",
    "plot_pred_true(test_pred.flatten(), test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is by far the best result so far. It seems that location brought in some new information, giving us significantly more predictive power.\n",
    "\n",
    "We are close to the end of all standard techniques (maybe some of the features we've modeled as reals should really be ordinals), but there is one more type of data that we haven't utilized yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## g) Text\n",
    "\n",
    "The following columns consist of long-form textual descriptions:\n",
    "\n",
    "  - name\n",
    "  - summary\n",
    "  - space\n",
    "  - neighborhood_overview\n",
    "  - notes\n",
    "  - transit\n",
    "  - access\n",
    "  - interaction\n",
    "  - house_rules\n",
    "\n",
    "We will experiment with using features from a pretrained neural network to represent this data.\n",
    "The neural network has learned an internal representation (say, at some hidden layer of the network) that it uses to make its predictions on a different task (such as sentiment prediction for sentences). \n",
    "\n",
    "We will use this internal representation directly for our task of AirBnB price prediction.\n",
    "Using an internal representation from an unrelated model as a feature is a common technique known as transfer learning.\n",
    "\n",
    "We will use pretrained features from the Universal Sentence Encoder (USE), which was designed explicitly for transfer learning to different tasks. \n",
    "[This paper](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46808.pdf) documents how this neural network architecture was designed and trained: \n",
    "This network consumes text of arbitrary length, and produces a feature vector of length $512$. \n",
    "\n",
    "Your TAs have precomputed these features for all of the columns above into the table \"airbnb-use-embeddings.csv\",\n",
    "available [as a zip file on the course website](https://people.orie.cornell.edu/mru8/orie4741/homework/airbnb-use-embeddings.zip).\n",
    "The id of each AirBnB listing is provided, along with features with names of the form \"column_number:feature_number\". That is, the 468th feature of the 5th text data column (also known as the \"name\" column) will be found at '5:468'.\n",
    "\n",
    "You can use [this demo code](https://tfhub.dev/google/universal-sentence-encoder/2)) to explore the USE embedding further. If you would like to use this (or any other) embedding for your project, you are welcome to come to Office Hours and we will gladly help you with your project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returning to the AirBnB dataset, we can import the data into a new dataframe. Since our training data has been shuffled, we use a dataset join to assemble the data below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tf = pd.read_csv(\"airbnb-use-embeddings.csv\") # Will take a while to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all = train_x.merge(df_tf, on='id',how='left')\n",
    "test_all = test_x.merge(df_tf, on='id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of original features \\t', len(train_x.columns))\n",
    "\n",
    "train_embed = np.array(train_all.iloc[:, len(train_x.columns):])\n",
    "test_embed = np.array(test_all.iloc[:, len(train_x.columns):])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find out how useful these parameters are (or aren't), fit a linear model of price as a function of embedding only (with offset!). Keep in mind that due to the sheer number of parameters to fit, **this step may take several minutes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embed_only = \n",
    "test_embed_only =\n",
    "\n",
    "train_MSE, test_MSE, test_pred = run_OLS(train_y, test_y, train_embed_only, test_embed_only)\n",
    "\n",
    "print(\"Train MSE\\t\", str(train_MSE))\n",
    "print(\"Test MSE\\t\", str(test_MSE))\n",
    "\n",
    "plot_pred_true(test_pred.flatten(), test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two things are readily apparent: this embedding provides a lot of information, but we are massively overfitting. This is to be expected: after all we have $4689$ parameters to fit, but only $20000$ training points.\n",
    "\n",
    "Now, it's important to know whether this embedding is just capturing informaation more succinctly stored in the other columns, or whether its capturing something genuinely novel. For that, you will need to fit a function using all of the parameters currently at your disposal, then compute MSE and plot the predicted vs expected score. **This step may take several minutes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vals = \n",
    "\n",
    "test_vals ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_MSE, test_MSE, test_pred = run_OLS(train_y, test_y, train_vals, test_vals)\n",
    "\n",
    "print(\"Train MSE\\t\", str(train_MSE))\n",
    "print(\"Test MSE\\t\", str(test_MSE))\n",
    "\n",
    "plot_pred_true(test_pred.flatten(), test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h) Further improvements?\n",
    "\n",
    "In the above parts, we have seen the strength of adding more (useful) features in improving both training and test performance. In this part, we want to test the idea of whether we can further improve our model by not adding more features, but making wise use of the features.\n",
    "\n",
    "First, we prepare a data-subsampled dataset with only 20% of the training and test data points retained. This saves time for us to test more settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sampling_ratio = 0.20\n",
    "train_n_rows_to_sample = int(round(data_sampling_ratio * train_vals.shape[0]))\n",
    "train_idx_rows_to_sample = rand.sample(list(range(len(train_vals))), train_n_rows_to_sample)\n",
    "\n",
    "train_vals_real_small = train_vals_real[train_idx_rows_to_sample, :]\n",
    "train_vals_from_string_small = train_vals_from_string[train_idx_rows_to_sample, :]\n",
    "train_bv_small = train_bv[train_idx_rows_to_sample, :]\n",
    "train_cat_vals_small = train_cat_vals[train_idx_rows_to_sample, :]\n",
    "train_set_vals_small = train_set_vals[train_idx_rows_to_sample, :]\n",
    "train_zip_small = train_zip[train_idx_rows_to_sample, :];\n",
    "train_embed_small = train_embed[train_idx_rows_to_sample, :]\n",
    "\n",
    "train_vals_small = np.concatenate((train_vals_real_small, \n",
    "                train_vals_from_string_small, \n",
    "                train_bv_small,\n",
    "                train_cat_vals_small,\n",
    "                train_set_vals_small, \n",
    "                train_zip_small,\n",
    "                train_embed_small,\n",
    "                np.ones(len(train_vals_real_small)).reshape([len(train_vals_real_small),1]) ), axis=1)\n",
    "\n",
    "train_y_small = train_y.iloc[train_idx_rows_to_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat with test set\n",
    "data_sampling_ratio = 0.20\n",
    "test_n_rows_to_sample = int(round(data_sampling_ratio * test_vals.shape[0]))\n",
    "test_idx_rows_to_sample = rand.sample(list(range(len(test_vals))), test_n_rows_to_sample)\n",
    "\n",
    "test_vals_real_small = test_vals_real[test_idx_rows_to_sample, :]\n",
    "test_vals_from_string_small = test_vals_from_string[test_idx_rows_to_sample, :]\n",
    "test_bv_small = test_bv[test_idx_rows_to_sample, :]\n",
    "test_cat_vals_small = test_cat_vals[test_idx_rows_to_sample, :]\n",
    "test_set_vals_small = test_set_vals[test_idx_rows_to_sample, :]\n",
    "test_zip_small = test_zip[test_idx_rows_to_sample, :];\n",
    "test_embed_small = test_embed[test_idx_rows_to_sample, :]\n",
    "\n",
    "test_vals_small = np.concatenate((test_vals_real_small, \n",
    "                test_vals_from_string_small, \n",
    "                test_bv_small,\n",
    "                test_cat_vals_small,\n",
    "                test_set_vals_small, \n",
    "                test_zip_small,\n",
    "                test_embed_small,\n",
    "                np.ones(len(test_vals_real_small)).reshape([len(test_vals_real_small),1]) ), axis=1)\n",
    "\n",
    "test_y_small = test_y.iloc[test_idx_rows_to_sample]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we train the linear regressor on the subsampled training set, and take a look at training and test MSEs. Despite the fact we shrunk our dataset, **this step may take a few minutes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_MSE_small, test_MSE_small, test_pred_small = run_OLS(train_y_small, test_y_small, train_vals_small, test_vals_small)\n",
    "\n",
    "print(\"Train MSE\\t\", str(train_MSE_small))\n",
    "print(\"Test MSE\\t\", str(test_MSE_small))\n",
    "\n",
    "plot_pred_true(test_pred_small.flatten(), test_y_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION H1)**: Compare the training and test MSEs on the data-subsampled dataset with those on the original dataset: the one that includes all data points and all features, as you did in the cell above the heading of this section. For these two fitted models, are they overfitting or underfitting? Which one over/underfits more? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR RESPONSE:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we are going to try first is to randomly select only a subset of the **text embedding** features for model fitting and prediction. In the next cell, randomly sample 10% of the text embedding features **from the data-subsampled training and test datasets** (so that the following steps would not take too much time) and **retain all the other features (including the offest)**. We call this the entire data-subsampled dataset (i.e., not feature-subsampled) in the following context. Then, use the new set of features to fit a linear regression model on the training set and predict on the test set. Print the training and test MSEs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, test on a collection of the number of text embedding features to sample, and plot the change of train and test MSEs. This may take several minutes, but you would not need to do it multiple times as long as your code in the above cell works well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_MSE_sub_all = []\n",
    "test_MSE_sub_all = []\n",
    "\n",
    "# the collection of number of text embedding features to sample\n",
    "n_embed_to_sample_all = [10, 50, 100, 200, 500, 1000, 2000, 3000, 4000]\n",
    "\n",
    "for n_embed_to_sample in n_embed_to_sample_all:\n",
    "    print(\"Number of text embedding features to sample: \", str(n_embed_to_sample))\n",
    "    idx_embed_to_sample = \n",
    "    \n",
    "    train_embed_sub = \n",
    "    test_embed_sub = \n",
    "    \n",
    "    train_vals_sub = \n",
    "    \n",
    "    test_vals_sub = \n",
    "    \n",
    "    train_MSE, test_MSE, test_pred_sub = run_OLS(train_y_small, test_y_small, train_vals_sub, test_vals_sub)\n",
    "    \n",
    "    print(\"Train MSE\\t\", str(train_MSE))\n",
    "    print(\"Test MSE\\t\", str(test_MSE))\n",
    "    \n",
    "    train_MSE_sub_all.append(train_MSE)\n",
    "    test_MSE_sub_all.append(test_MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, plot the change of train and test MSEs with the number of sampled features, together with two horizontal lines showing the train and test MSEs on the entire data-subsampled dataset (i.e., not feature-subsampled). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION H2)**: \n",
    "- In the plot you get above:does the model over/underfit worse when the number of sampled text embedding feature increases?  Why?\n",
    "- Compared to the model performance on the entire data-subsampled dataset (i.e., not feature-subsampled), how does feature subsampling work, in terms of prediction error and generalization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR RESPONSE:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we explore a \"smarter\" way of reducing the number of features using Principal Component Analysis (PCA) to embed the features. PCA projects the data onto a subspace of maximal variance, preserving as much signal as possible in fewer dimensions. We'll cover PCA later in the course.\n",
    "\n",
    "In the next cell, compute the Singular Value Decomposition (SVD) of the embedding features by using np.linalg.svd(). It may take a couple of trys to converge, so be aware that this cell **may take several minutes to run.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, test on a collection of the rank of the PCA to use, and plot the change of train and test MSEs. **This may take several minutes.** In particular, take the first $k$ columns of $V$ where $USV^T$ is the SVD of the embedding feature matrix and right multiply the embedding feature matrix with the first $k$ columns of $V$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_MSE_pca_all = []\n",
    "test_MSE_pca_all = []\n",
    "\n",
    "print('Train MSE on the data-subsampled dataset \\t', str(train_MSE_small))\n",
    "print('Test MSE on the data-subsampled dataset \\t', str(test_MSE_small))\n",
    "\n",
    "k_all = [10, 50, 100, 500, 1000]\n",
    "\n",
    "for k in k_all:\n",
    "    print(k)\n",
    "    \n",
    "    V_k = \n",
    "    \n",
    "    train_embed_pca =  \n",
    "    test_embed_pca = \n",
    "\n",
    "    train_vals_pca = \n",
    "    \n",
    "    test_vals_pca = \n",
    "    \n",
    "    train_MSE, test_MSE, test_pred_sub = run_OLS(train_y_small, test_y_small, train_vals_pca, test_vals_pca)\n",
    "    \n",
    "    print(\"Train MSE\\t\", str(train_MSE))\n",
    "    print(\"Test MSE\\t\", str(test_MSE))\n",
    "    \n",
    "    train_MSE_pca_all.append(train_MSE)\n",
    "    test_MSE_pca_all.append(test_MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, plot the change of train and test MSEs in the PCA case, in the same way as random sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION H3)**: \n",
    "- In the PCA plot you get above, does the model over/underfits worse when the number of sampled text embedding feature increases? \n",
    "- Compared to randomly sampling the text embedding features, how does PCA works, in terms of prediction error and generalization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR RESPONSE:** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
