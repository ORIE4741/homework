{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SVD vs. AM\n",
    "\n",
    "In class, you learned about two ways of solving PCA. Let's compare them. The data you will use is from part h of the airbnb homework. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'airbnb_hw6.csv' contains the full dataset we will use throughout this assignment (Y_full). Because it is big, we will start by only looking at the first third of the data (Y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "Y_full = pd.read_csv('airbnb_hw6.csv', header=None)\n",
    "n_full, d = Y_full.shape\n",
    "Y = Y_full.iloc[0:n_full//3]\n",
    "\n",
    "Y = Y.to_numpy()\n",
    "Y_full = Y_full.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Top-k SVD and residual error.\n",
    "For the airbnb data and for $k = 1,2,...,10$, compute the top-k SVD \n",
    "$U_k \\Sigma_k V_k^T$\n",
    "and the residual error\n",
    "$||Y - U_k \\Sigma_k V_k^T||.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Plot the residual error as a function of $k$. \n",
    "What do you observe? Would you say the top $k$ SVD is a good approximation?  For what $k$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Alternating minimization\n",
    "\n",
    "Set $k=10$. Generate a random starting matrix $W \\in \\mathbb{R}^{k \\times d}$ with `np.random.randn`. Use least squares to solve \n",
    "$$ \\mbox{minimize}\\quad\\|Y - XW\\|_F^2 $$\n",
    "for $X$. Now fix that $X$ and use least squares to solve for $W$. Repeat this 10 times (ie, 10 solves each for $X$ and $W$). (Cache the Gram matrix for each least squares problem for a faster solve!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Plot the residual error $|| Y - XW ||$ as a function of iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) How do the two methods compare?\n",
    "\n",
    "In particular, compare the residual error when $k=10$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f) PCA on the full dataset (approximately)\n",
    "\n",
    "Ideally, we would like to apply PCA to the full dataset, but even the small subset takes a while.\n",
    "\n",
    "In the AM method, $W$ has as many columns as $Y$, while $X$ has as many rows as $Y$. The full dataset has more rows, so we could fix the same $W$ we derived for the small dataset, and use this to find $X_\\text{full}$ for the full dataset by solving \n",
    "$$\\mbox{minimize} \\|Y_\\text{full} - X_\\text{full} W\\|_F^2 $$\n",
    "with variable $X$.\n",
    "That is, we fix $W$ and take one more step of AM (using $Y_\\text{full}$) to compute $X_{full}$. \n",
    "\n",
    "How does the new average residual error per row compare to the previous average residual error per row?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
